# spark-pi.yaml

apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-pi
spec:
  type: Python
  mode: cluster
  image: "noyusu/pyspark:2024-04-17.10-23-09"
  imagePullPolicy: Always
  mainClass: org.apache.spark.examples.SparkPi
  mainApplicationFile: "local:///workspace/pyspark/read-dataset.py"
  sparkVersion: "3.2.4"
  restartPolicy:
    type: Never
  arguments:
    - "--config"
    - "./config.json"
  sparkConf:
    "spark.default.parallelism": "40"
    "spark.sql.shuffle.partitions": "40"
    "spark.scheduler.mode": "FAIR"
    "spark.kubernetes.local.dirs.tmpfs": "true"
  volumes:
    - name: "test-volume"
      hostPath:
        path: "/tmp"
        type: Directory
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    labels:
      version: 3.2.4
    serviceAccount: spark
    volumeMounts:
      - name: "test-volume"
        mountPath: "/tmp"
  executor:
    cores: 4
    instances: 5
    memory: "9g"
    labels:
      version: 3.2.4
    volumeMounts:
      - name: "test-volume"
        mountPath: "/tmp"
  deps:
    jars:
      - "https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.12/10.2.2/mongo-spark-connector_2.12-10.2.2.jar,https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-sync/4.8.2/mongodb-driver-sync-4.8.2.jar,https://repo1.maven.org/maven2/org/mongodb/bson/4.8.2/bson-4.8.2.jar,https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-core/4.8.2/mongodb-driver-core-4.8.2.jar,https://repo1.maven.org/maven2/org/mongodb/bson-record-codec/4.8.2/bson-record-codec-4.8.2.jar"